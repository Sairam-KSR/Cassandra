{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Cassandra"
      ],
      "metadata": {
        "id": "gnbk0jieuyxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Cassandra Drivers\n"
      ],
      "metadata": {
        "id": "uJwH9X0bx0Fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVtJcsxYfme9",
        "outputId": "1edba12d-96eb-4ee0-b00b-9e47e6d24f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cassandra-driver in /usr/local/lib/python3.10/dist-packages (3.29.2)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver) (0.2.1.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cassandra-driver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "UDkVLO0RLZC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n"
      ],
      "metadata": {
        "id": "twzFRgwmfsRe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up a connection"
      ],
      "metadata": {
        "id": "VG2C8GFs_T8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_connection():\n",
        "  try:\n",
        "\n",
        "    cloud_config= {\n",
        "      'secure_connect_bundle': 'secure-connect-mydb.zip'\n",
        "    }\n",
        "    #Initialize the token downloaded\n",
        "    with open(\"mydb-token.json\") as f:\n",
        "        secrets = json.load(f)\n",
        "\n",
        "    CLIENT_ID = secrets[\"clientId\"]\n",
        "    CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "    auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "    session = cluster.connect()\n",
        "    if session:\n",
        "      print(\"Connection Established !!\")\n",
        "    else:\n",
        "      print(\"Connection Failed !!\")\n",
        "    return session\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None\n",
        "\n"
      ],
      "metadata": {
        "id": "t-g8t8Duft8o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = get_connection()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7fZysIn0CHl",
        "outputId": "9819c179-bf36-4742-f413-98a6b42a43ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 0fce8e6c-7e10-40ac-a56f-a8492eecba58-eu-west-1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 0fce8e6c-7e10-40ac-a56f-a8492eecba58-eu-west-1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 0fce8e6c-7e10-40ac-a56f-a8492eecba58-eu-west-1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection Established !!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bronze Flow"
      ],
      "metadata": {
        "id": "21GUJcmV02V5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Raw data from URL"
      ],
      "metadata": {
        "id": "WxioDKoh1N2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "def raw_data():\n",
        "    try:\n",
        "        url = 'https://raw.githubusercontent.com/gchandra10/filestorage/main/sales_100.csv'\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            try:\n",
        "                data = pd.read_csv(StringIO(response.text), delimiter=',')\n",
        "                print(\"Data retrieved successfully !!\")\n",
        "                return data\n",
        "            except Exception as e:\n",
        "                print(\"An error occurred while parsing the CSV:\", e)\n",
        "        else:\n",
        "            print(\"Failed to retrieve data, HTTP Status Code:\", response.status_code)\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred during data retrieval:\", e)\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "r4qkZp3efwO8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Table"
      ],
      "metadata": {
        "id": "u2Mqli2I04vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.execute(\"drop table if exists bigdata.sales100_bronze\")\n",
        "session.execute(\"drop table if exists bigdata.sales100_silver\")\n",
        "session.execute(\"drop table if exists bigdata.sales100_gold\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXOZmEdjkyAy",
        "outputId": "ef5a6130-c7b4-4b68-f007-cf08c6031abc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.ResultSet at 0x7cb63d5e0f70>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_table(session,table_name):\n",
        "    create_table_cql = f\"\"\"\n",
        "      CREATE TABLE IF NOT EXISTS {table_name} (\n",
        "        region TEXT,\n",
        "        country TEXT,\n",
        "        item_type TEXT,\n",
        "        sales_channel TEXT,\n",
        "        order_priority TEXT,\n",
        "        order_date TEXT,\n",
        "        order_id BIGINT,\n",
        "        ship_date TEXT,\n",
        "        units_sold INT,\n",
        "        unit_price FLOAT,\n",
        "        unit_cost FLOAT,\n",
        "        total_revenue FLOAT,\n",
        "        total_cost FLOAT,\n",
        "        total_profit FLOAT,\n",
        "        PRIMARY KEY (order_id)\n",
        "      );\n",
        "    \"\"\"\n",
        "    try:\n",
        "        session.execute(create_table_cql)\n",
        "        print(f\"{table_name} Table created successfully !!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create table: {e}\")\n"
      ],
      "metadata": {
        "id": "UdJuHtNFfyta"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning column names"
      ],
      "metadata": {
        "id": "u4NECGy21V5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_column_names(data):\n",
        "  try:\n",
        "    data.columns = data.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "    print(\"Column names cleaned successfully !!\")\n",
        "    return data\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "jpsmNVB8gzPY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Pre Processing : Changing date format"
      ],
      "metadata": {
        "id": "xNrWeafI1ZDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing(data):\n",
        "  try:\n",
        "    data['order_date'] = pd.to_datetime(data['order_date']).dt.strftime('%Y-%m-%d')\n",
        "    data['ship_date'] = pd.to_datetime(data['ship_date']).dt.strftime('%Y-%m-%d')\n",
        "    return data\n",
        "  except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "EYKCFUJag_Q3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert Bronze Data : Raw Data insertion from URL to Bronze table"
      ],
      "metadata": {
        "id": "Kj2HwMxP1fkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_bronze_data(session, data, table_name):\n",
        "    query = session.prepare(f\"\"\"\n",
        "        INSERT INTO {table_name} (region, country, item_type, sales_channel, order_priority, order_date, order_id,\n",
        "                                  ship_date, units_sold, unit_price, unit_cost, total_revenue, total_cost, total_profit)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n",
        "    \"\"\")\n",
        "    try:\n",
        "        for index, row in data.iterrows():\n",
        "            session.execute(query, (\n",
        "                row['region'], row['country'], row['item_type'], row['sales_channel'],\n",
        "                row['order_priority'], row['order_date'], row['order_id'], row['ship_date'],\n",
        "                row['unitssold'], row['unitprice'], row['unitcost'], row['totalrevenue'],\n",
        "                row['totalcost'], row['totalprofit']))\n",
        "        print(\"Bronze Data inserted successfully for all rows.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to insert data: {e}\")\n"
      ],
      "metadata": {
        "id": "KW5vb8_Ff7nu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Silver Flow"
      ],
      "metadata": {
        "id": "ZGNhiYVe37k9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to Dataframe : Converting result set into data frame  "
      ],
      "metadata": {
        "id": "0OjCuGCUmyfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_dataframe(session,table_name):\n",
        "  try:\n",
        "    result = session.execute(f\"SELECT * FROM {table_name}\")\n",
        "    df = pd.DataFrame(result)\n",
        "    df['order_date'] = pd.to_datetime(df['order_date']).dt.strftime('%Y-%m-%d')\n",
        "    df['ship_date'] = pd.to_datetime(df['ship_date']).dt.strftime('%Y-%m-%d')\n",
        "    print(\"Data converted successfully !!\")\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "RXXx0LZLlB3O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Round Col : Round off the decimal values"
      ],
      "metadata": {
        "id": "L9L-8m2cm6sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round_col(df):\n",
        "  try:\n",
        "    for col in df.columns:\n",
        "      if pd.api.types.is_numeric_dtype(df[col]):\n",
        "        df[col] = df[col].round(2)\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None"
      ],
      "metadata": {
        "id": "5BBvPw7-lF37"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean Bronze : Bronze Data Cleaning"
      ],
      "metadata": {
        "id": "p57xpLqe3vIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_bronze(session,bronze_table):\n",
        "  try:\n",
        "\n",
        "    df = convert_to_dataframe(session,\"bigdata.sales100_bronze\")\n",
        "    df = round_col(df)\n",
        "    print(\"Bronze Data cleaned successfully !!\")\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None"
      ],
      "metadata": {
        "id": "UOZLHKq718QW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert Silver Data : Cleaned data insertion in silver table"
      ],
      "metadata": {
        "id": "xRGmuEYh-bnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_silver_data(session, data, table_name):\n",
        "    query = session.prepare(f\"\"\"\n",
        "        INSERT INTO {table_name} (region, country, item_type, sales_channel, order_priority, order_date, order_id,\n",
        "                                  ship_date, units_sold, unit_price, unit_cost, total_revenue, total_cost, total_profit)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n",
        "    \"\"\")\n",
        "    try:\n",
        "        for index, row in data.iterrows():\n",
        "            session.execute(query, (\n",
        "                row['region'], row['country'], row['item_type'], row['sales_channel'],\n",
        "                row['order_priority'], row['order_date'], row['order_id'], row['ship_date'],\n",
        "                row['units_sold'], row['unit_price'], row['unit_cost'], row['total_revenue'],\n",
        "                row['total_cost'], row['total_profit']))\n",
        "        print(\"Silver Data inserted successfully for all rows.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to insert data: {e}\")\n"
      ],
      "metadata": {
        "id": "6cuLoMxcavdW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gold Flow"
      ],
      "metadata": {
        "id": "hkns8gHD4FVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Table Gold : Create Gold Table"
      ],
      "metadata": {
        "id": "NHmHP-3wssCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_table_gold(session):\n",
        "    create_table_cqls = [\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS bigdata.sales100_gold_yearly (\n",
        "            year INT,\n",
        "            region TEXT,\n",
        "            total_sales FLOAT,\n",
        "            average_unit_price FLOAT,\n",
        "            PRIMARY KEY (year, region)\n",
        "        );\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS bigdata.sales100_gold_monthly (\n",
        "            year INT,\n",
        "            month INT,\n",
        "            region TEXT,\n",
        "            total_sales FLOAT,\n",
        "            average_unit_price FLOAT,\n",
        "            PRIMARY KEY ((year, month), region)\n",
        "        );\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS bigdata.sales100_gold_country (\n",
        "            country TEXT,\n",
        "            year INT,\n",
        "            total_sales FLOAT,\n",
        "            average_unit_price FLOAT,\n",
        "            PRIMARY KEY (country, year)\n",
        "        );\n",
        "        \"\"\"\n",
        "    ]\n",
        "    try:\n",
        "        for cql in create_table_cqls:\n",
        "            session.execute(cql)\n",
        "        print(\"Gold tables created successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create gold tables: {e}\")\n"
      ],
      "metadata": {
        "id": "vszmJ7-fVFn8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Gold Data : Data transformation from gold to silver"
      ],
      "metadata": {
        "id": "xyXmmtU-su5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_gold_data1(silver_df):\n",
        "    try:\n",
        "        silver_df['order_date'] = pd.to_datetime(silver_df['order_date'])\n",
        "        silver_df['year'] = silver_df['order_date'].dt.year\n",
        "        silver_df['month'] = silver_df['order_date'].dt.month\n",
        "\n",
        "        yearly_grouped = silver_df.groupby(['year', 'region']).agg(\n",
        "            total_sales=pd.NamedAgg(column='total_revenue', aggfunc='sum'),\n",
        "            average_unit_price=pd.NamedAgg(column='unit_price', aggfunc='mean')\n",
        "        ).reset_index()\n",
        "        print(\"Gold data 1 prepared successfully.\")\n",
        "        return yearly_grouped\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "5VRl-rz4VK7A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_gold_data2(silver_df):\n",
        "    try:\n",
        "        silver_df['order_date'] = pd.to_datetime(silver_df['order_date'])\n",
        "        silver_df['year'] = silver_df['order_date'].dt.year\n",
        "        silver_df['month'] = silver_df['order_date'].dt.month\n",
        "\n",
        "        monthly_grouped = silver_df.groupby(['year', 'month', 'region']).agg(\n",
        "            total_sales=pd.NamedAgg(column='total_revenue', aggfunc='sum'),\n",
        "            average_unit_price=pd.NamedAgg(column='unit_price', aggfunc='mean')\n",
        "        ).reset_index()\n",
        "        print(\"Gold data 2 prepared successfully.\")\n",
        "        return monthly_grouped\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "ZLPeUNhWV-qv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_gold_data3(silver_df):\n",
        "  try:\n",
        "    silver_df['order_date'] = pd.to_datetime(silver_df['order_date'])\n",
        "    silver_df['year'] = silver_df['order_date'].dt.year\n",
        "    silver_df['month'] = silver_df['order_date'].dt\n",
        "    country_grouped = silver_df.groupby(['country', 'year']).agg(\n",
        "            total_sales=pd.NamedAgg(column='total_revenue', aggfunc='sum'),\n",
        "            average_unit_price=pd.NamedAgg(column='unit_price', aggfunc='mean')\n",
        "        ).reset_index()\n",
        "\n",
        "    print(\"Gold data 3 prepared successfully.\")\n",
        "    return country_grouped\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None\n",
        "\n"
      ],
      "metadata": {
        "id": "rVsomlsFWVrb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert gold data : Insert data into gold table"
      ],
      "metadata": {
        "id": "x32JM7rHqg1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_gold_data1(session, yearly_data):\n",
        "    yearly_query = session.prepare(\"\"\"\n",
        "        INSERT INTO bigdata.sales100_gold_yearly (year, region, total_sales, average_unit_price)\n",
        "        VALUES (?, ?, ?, ?);\n",
        "    \"\"\")\n",
        "\n",
        "    try:\n",
        "        for idx, row in yearly_data.iterrows():\n",
        "            session.execute(yearly_query, (row['year'], row['region'], row['total_sales'], row['average_unit_price']))\n",
        "\n",
        "        print(\"Data inserted successfully into the gold table1.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to insert gold data: {e}\")\n"
      ],
      "metadata": {
        "id": "xlQwSuF4XrCE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_gold_data2(session, monthly_data):\n",
        "\n",
        "    monthly_query = session.prepare(\"\"\"\n",
        "        INSERT INTO bigdata.sales100_gold_monthly (year, month, region, total_sales, average_unit_price)\n",
        "        VALUES (?, ?, ?, ?, ?);\n",
        "    \"\"\")\n",
        "\n",
        "    try:\n",
        "\n",
        "        for idx, row in monthly_data.iterrows():\n",
        "            session.execute(monthly_query, (row['year'], row['month'], row['region'], row['total_sales'], row['average_unit_price']))\n",
        "\n",
        "        print(\"Data inserted successfully into the gold tables.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to insert gold data: {e}\")\n"
      ],
      "metadata": {
        "id": "RgRI0b92XnZz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_gold_data3(session, country_data):\n",
        "\n",
        "    country_query = session.prepare(\"\"\"\n",
        "        INSERT INTO bigdata.sales100_gold_country (country, year, total_sales, average_unit_price)\n",
        "        VALUES (?, ?, ?, ?);\n",
        "    \"\"\")\n",
        "\n",
        "    try:\n",
        "\n",
        "        for idx, row in country_data.iterrows():\n",
        "            session.execute(country_query, (row['country'], row['year'], row['total_sales'], row['average_unit_price']))\n",
        "        print(\"Data inserted successfully into the gold tables.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to insert gold data: {e}\")\n"
      ],
      "metadata": {
        "id": "9lZLIqZLVRuL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bronze Operations"
      ],
      "metadata": {
        "id": "RhVF2vs8s3fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bronze(session):\n",
        "  try:\n",
        "    # Get data from URL\n",
        "    data = raw_data()\n",
        "    print(\"Raw Data fetched successfully !!\")\n",
        "\n",
        "    data = clean_column_names(data)\n",
        "    data = data_preprocessing(data)\n",
        "\n",
        "    bronze_table = create_table(session,\"bigdata.sales100_bronze\")\n",
        "    print(\"Bronze Table created successfully !!\")\n",
        "    bronze_table=insert_bronze_data(session, data, 'bigdata.sales100_bronze')\n",
        "\n",
        "    return bronze_table\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None"
      ],
      "metadata": {
        "id": "ez6gDxddf2p-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Silver Operations"
      ],
      "metadata": {
        "id": "0V1-jpQOs63Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def silver(session,bronze_table):\n",
        "  try:\n",
        "    silver_data = clean_bronze(session,bronze_table)\n",
        "    silver_table = create_table(session,\"bigdata.sales100_silver\")\n",
        "    print(\"Silver Table created successfully !!\")\n",
        "    silver_table=insert_silver_data(session, silver_data, 'bigdata.sales100_silver')\n",
        "    return silver_table\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "D6ZIjnWc6gAp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gold Operations"
      ],
      "metadata": {
        "id": "MWjbZUL2s9jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gold(session, silver_table):\n",
        "    try:\n",
        "        silver_df = convert_to_dataframe(session, \"bigdata.sales100_silver\")\n",
        "        print(\"Silver converted to dataframe.\")\n",
        "        yearly_gold_data = data_preprocessing(silver_df)\n",
        "        yearly_gold_data = prepare_gold_data1(yearly_gold_data)\n",
        "\n",
        "        monthly_gold_data = data_preprocessing(silver_df)\n",
        "        monthly_gold_data = prepare_gold_data2(monthly_gold_data)\n",
        "\n",
        "        country_gold_data = data_preprocessing(silver_df)\n",
        "        country_gold_data = prepare_gold_data3(country_gold_data)\n",
        "\n",
        "        create_table_gold(session)\n",
        "        print(\"Gold tables created.\")\n",
        "\n",
        "        insert_gold_data1(session, yearly_gold_data)\n",
        "        insert_gold_data2(session, monthly_gold_data)\n",
        "        insert_gold_data3(session, country_gold_data)\n",
        "        print(\"Gold data inserted successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "6EFw7HtnVVXB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table view\n"
      ],
      "metadata": {
        "id": "-dXoiSEv3Qdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def table_view(session,table_name):\n",
        "  try:\n",
        "    result = session.execute(f\"SELECT * FROM {table_name} limit 2\")\n",
        "    for row in result:\n",
        "      print(row)\n",
        "  except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "Qa72pKybxDew"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Meddallian Architecture"
      ],
      "metadata": {
        "id": "cPLZwcRVtA-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Medallion Architecture \")\n",
        "    print('\\n')\n",
        "    # Bronze\n",
        "    bronze_table = bronze(session)\n",
        "    print('--------  Bronze Table ---------\\n')\n",
        "    table_view(session,\"bigdata.sales100_bronze\")\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "    # Silver\n",
        "    silver_table = silver(session, bronze_table)\n",
        "    print('--------  Silver Table ---------\\n')\n",
        "    table_view(session,\"bigdata.sales100_silver\")\n",
        "    print('\\n')\n",
        "\n",
        "    # Gold\n",
        "    gold_table = gold(session, silver_table)\n",
        "    print('--------  Gold Table Yearly ---------\\n')\n",
        "    table_view(session,\"bigdata.sales100_gold_yearly\")\n",
        "    print('--------  Gold Table Monthly ---------\\n')\n",
        "    table_view(session,\"bigdata.sales100_gold_monthly\")\n",
        "    print('--------  Gold Table Country ---------\\n')\n",
        "    table_view(session,\"bigdata.sales100_gold_country\")\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7SVcLNLmQnA",
        "outputId": "a1911407-00c2-4901-a097-64f87bc42ef9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medallion Architecture \n",
            "\n",
            "\n",
            "Data retrieved successfully !!\n",
            "Raw Data fetched successfully !!\n",
            "Column names cleaned successfully !!\n",
            "bigdata.sales100_bronze Table created successfully !!\n",
            "Bronze Table created successfully !!\n",
            "Bronze Data inserted successfully for all rows.\n",
            "--------  Bronze Table ---------\n",
            "\n",
            "Row(order_id=294530856, country='Italy', item_type='Cereal', order_date='2011-11-15', order_priority='M', region='Europe', sales_channel='Online', ship_date='2011-12-28', total_cost=829138.8125, total_profit=627217.1875, total_revenue=1456356.0, unit_cost=117.11000061035156, unit_price=205.6999969482422, units_sold=7080)\n",
            "Row(order_id=274930989, country='Dominica', item_type='Household', order_date='2011-11-19', order_priority='C', region='Central America and the Caribbean', sales_channel='Offline', ship_date='2011-12-13', total_cost=3539891.75, total_profit=1167402.125, total_revenue=4707294.0, unit_cost=502.5400085449219, unit_price=668.27001953125, units_sold=7044)\n",
            "\n",
            "\n",
            "Data converted successfully !!\n",
            "Bronze Data cleaned successfully !!\n",
            "bigdata.sales100_silver Table created successfully !!\n",
            "Silver Table created successfully !!\n",
            "Silver Data inserted successfully for all rows.\n",
            "--------  Silver Table ---------\n",
            "\n",
            "Row(order_id=294530856, country='Italy', item_type='Cereal', order_date='2011-11-15', order_priority='M', region='Europe', sales_channel='Online', ship_date='2011-12-28', total_cost=829138.8125, total_profit=627217.1875, total_revenue=1456356.0, unit_cost=117.11000061035156, unit_price=205.6999969482422, units_sold=7080)\n",
            "Row(order_id=274930989, country='Dominica', item_type='Household', order_date='2011-11-19', order_priority='C', region='Central America and the Caribbean', sales_channel='Offline', ship_date='2011-12-13', total_cost=3539891.75, total_profit=1167402.125, total_revenue=4707294.0, unit_cost=502.5400085449219, unit_price=668.27001953125, units_sold=7044)\n",
            "\n",
            "\n",
            "Data converted successfully !!\n",
            "Silver converted to dataframe.\n",
            "Gold data 1 prepared successfully.\n",
            "Gold data 2 prepared successfully.\n",
            "Gold data 3 prepared successfully.\n",
            "Gold tables created successfully!\n",
            "Gold tables created.\n",
            "Data inserted successfully into the gold table1.\n",
            "Data inserted successfully into the gold tables.\n",
            "Data inserted successfully into the gold tables.\n",
            "Gold data inserted successfully.\n",
            "--------  Gold Table Yearly ---------\n",
            "\n",
            "Row(year=2014, region='Asia', average_unit_price=286.7350158691406, total_sales=10124372.0)\n",
            "Row(year=2014, region='Australia and Oceania', average_unit_price=205.6999969482422, total_sales=1168581.75)\n",
            "--------  Gold Table Monthly ---------\n",
            "\n",
            "Row(year=2011, month=9, region='Asia', average_unit_price=668.27001953125, total_sales=416332.21875)\n",
            "Row(year=2011, month=9, region='Europe', average_unit_price=668.27001953125, total_sales=6666661.5)\n",
            "--------  Gold Table Country ---------\n",
            "\n",
            "Row(country='Malaysia', year=2014, average_unit_price=47.45000076293945, total_sales=434357.3125)\n",
            "Row(country='Israel', year=2013, average_unit_price=47.45000076293945, total_sales=223442.046875)\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}